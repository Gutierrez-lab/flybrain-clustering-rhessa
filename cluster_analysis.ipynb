{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 06 21 14:56:46  Imports complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import collections\n",
    "from scipy import sparse as sp\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "from itertools import combinations, combinations_with_replacement, cycle\n",
    "from functools import reduce\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from util import log_msg, simplify_type\n",
    "log_msg(\"Imports complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 06 21 14:59:20  Hemibrain data set being used: v1.2.1\n",
      "2023 06 21 14:59:20  Set up directory info and useful lists\n"
     ]
    }
   ],
   "source": [
    "hemibrain_version = \"v1.2.1\"\n",
    "log_msg(\"Hemibrain data set being used:\", hemibrain_version)\n",
    "\n",
    "preproc_dir = \"oviIN/preprocessed-\" + hemibrain_version\n",
    "preproc_nodes = \"preprocessed_nodes.csv\"\n",
    "preproc_centroids = \"x\"\n",
    "preproc_edges = \"preprocessed_undirected_edges.csv\"\n",
    "\n",
    "hemibrain_dir = \"oviIN/clustering_\" + hemibrain_version\n",
    "hemibrain_nodes = \"inputsoutputs_key.txt\"\n",
    "hemibrain_edges = \"inputsoutputs.txt\"\n",
    "#hemibrain_nodes = \"only_inputs_key.txt\"\n",
    "#hemibrain_edges = \"only_inputs.txt\"\n",
    "#hemibrain_nodes = \"only_outputs_key.txt\"\n",
    "#hemibrain_edges = \"only_outputs.txt\"\n",
    "\n",
    "figure_dir = os.path.join(\"figures\",\"paper\")\n",
    "movie_dir = os.path.join(\"movies\")\n",
    "analysis_dir = os.path.join(\"analysis\",hemibrain_version)\n",
    "obj_dir = os.path.join(\"obj\",hemibrain_version)  # 3d objects from, e.g. fetch_roi_mesh\n",
    "skel_dir = os.path.join(\"skeleton\", hemibrain_version)  # skeleta of neurons in .csv format\n",
    "\n",
    "\n",
    "for d in [figure_dir, analysis_dir, obj_dir, movie_dir]:\n",
    "    if not os.path.isdir(d):\n",
    "        log_msg(\"Creating directory\", d)\n",
    "        os.makedirs(d)\n",
    "\n",
    "reneel_params = list(sorted(['0.0', '0.1','0.5','0.75'], key=float))\n",
    "type_params = ['celltype','instance']\n",
    "list_of_params = reneel_params + type_params\n",
    "\n",
    "log_msg(\"Set up directory info and useful lists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 06 21 14:59:21  neuprint Client set up as `np_Client`, version 0.1.0\n"
     ]
    }
   ],
   "source": [
    "from neuprint import Client\n",
    "from neuprint import fetch_roi_hierarchy\n",
    "\n",
    "\n",
    "auth_token_file = open(\"flybrain.auth.txt\", 'r')\n",
    "auth_token = next(auth_token_file).strip()\n",
    "try:\n",
    "    np_client = Client('neuprint.janelia.org', dataset='hemibrain:' + hemibrain_version, token=auth_token)\n",
    "    log_msg(\"neuprint Client set up as `np_Client`, version\", np_client.fetch_version())\n",
    "except:\n",
    "    np_client = None\n",
    "    log_msg(\"neuprint Client set up failed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 06 21 14:59:21  Loading node dataframe\n",
      "2023 06 21 14:59:21    (without centroids)\n",
      "2023 06 21 14:59:21  Adding 'type group'\n",
      "2023 06 21 14:59:21  Done!\n",
      "2023 06 21 14:59:21  Loading directed edges from csv\n",
      "2023 06 21 14:59:21  Done!\n",
      "2023 06 21 14:59:21  Merging in cell info to edge df\n",
      "2023 06 21 14:59:21  Done!\n"
     ]
    }
   ],
   "source": [
    "log_msg(\"Loading node dataframe\")\n",
    "if os.path.isfile(os.path.join(preproc_dir, preproc_centroids)):\n",
    "    log_msg(\"  (with centroids)\")\n",
    "    HB_node_df = pd.read_csv(os.path.join(preproc_dir, preproc_centroids), index_col=0)\n",
    "else:\n",
    "    log_msg(\"  (without centroids)\")\n",
    "    HB_node_df = pd.read_csv(os.path.join(preproc_dir, preproc_nodes), index_col=0)\n",
    "log_msg(\"Adding 'type group'\")\n",
    "HB_node_df[\"type_group\"] = HB_node_df[\"celltype\"].apply(simplify_type)\n",
    "log_msg(\"Done!\")\n",
    "\n",
    "log_msg(\"Loading directed edges from csv\")\n",
    "HB_edge_df = pd.read_csv(os.path.join(hemibrain_dir, hemibrain_edges), delimiter=' ', header=None).rename(columns={0: \"pre\", 1:\"post\"})\n",
    "log_msg(\"Done!\")\n",
    "\n",
    "log_msg(\"Merging in cell info to edge df\")\n",
    "HB_edge_df = HB_edge_df.merge(HB_node_df[list_of_params + ['type_group']], left_on='pre', right_index=True)\n",
    "HB_edge_df = HB_edge_df.merge(HB_node_df[list_of_params + ['type_group']], left_on='post', right_index=True, suffixes=['pre', 'post'])\n",
    "log_msg(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lists(clusters):\n",
    "    list_point1 = []\n",
    "    list_point5 = []\n",
    "    for i in clusters:\n",
    "        list_point1 += HB_node_df[HB_node_df['0.1']==i].index.tolist()\n",
    "        list_point5 += HB_node_df[HB_node_df['0.05']==i].index.tolist()\n",
    "    return list_point1, list_point5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning high res clusters to corresponding low res cluster\n",
    "cluster1 = [1,2,4,47]\n",
    "cluster2 = [3, 42, 133, 134]\n",
    "cluster3 = [5]\n",
    "cluster4 = [6, 115, 123]\n",
    "cluster5 = [7, 12, 13, 67]\n",
    "cluster6 = [8, 10, 48, 409]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1268"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_point1, li_point5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling cluster for all clusters at 0.0\n",
    "li_cluster1=HB_node_df[HB_node_df['0.0']==1].index\n",
    "li_cluster2=HB_node_df[HB_node_df['0.0']==2].index\n",
    "li_cluster3=HB_node_df[HB_node_df['0.0']==3].index\n",
    "li_cluster4=HB_node_df[HB_node_df['0.0']==4].index\n",
    "li_cluster5=HB_node_df[HB_node_df['0.0']==5].index\n",
    "li_cluster6=HB_node_df[HB_node_df['0.0']==6].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_difference(list, list2):\n",
    "    set1 = set(list)\n",
    "    set2 = set(list2)\n",
    "\n",
    "    unique_1 = set1-set2\n",
    "    unique_2 = set2-set1\n",
    "\n",
    "    common = set1.intersection(set2)\n",
    "    total_unique = len(unique_1) + len(unique_2)\n",
    "    jaccard_sim = len(common) / (total_unique + len(common))\n",
    "\n",
    "    return unique_1, unique_2, common, jaccard_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_1, unique_2, common, jaccard_sim = calculate_difference(li_point1, li_cluster1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neurons unique to list 1:  277\n",
      "Neurons unique to list 2:  187\n",
      "Length of common neurons: 991\n",
      "Jaccard similarity: 0.6810996563573883\n"
     ]
    }
   ],
   "source": [
    "print('Neurons unique to chi value of 0.1: ', len(unique_1))\n",
    "print('Neurons unique to chi value of 0.0 of cluster 1: ', len(unique_2))\n",
    "#print('Common neurons:', common)\n",
    "print('Length of common neurons:', len(common))\n",
    "print(\"Jaccard similarity:\", jaccard_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fbl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
